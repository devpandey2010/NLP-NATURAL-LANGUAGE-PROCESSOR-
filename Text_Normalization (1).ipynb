{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**WILL Undersatnd the concept of Text Normalization**\n",
        "\n",
        "LowerCasing\n",
        "\n",
        "Removing special characters\n",
        "\n",
        "Removing spaces(whitespaces)\n",
        "\n",
        "Expanding contractions\n",
        "\n",
        "handling Numbers\n",
        "\n",
        "Handling special characters\n",
        "\n",
        "spell checking\n",
        "\n",
        "**Why Do we need Text Normalization**\n",
        "\n",
        "Text Normalization is the process of converting raw, inconsistent text into a consistent format so that a model can understand it better.\n",
        "\n",
        "‚úÖ Why Text Normalization is Needed:\n",
        "1. üî§ Inconsistency in Text\n",
        "\"Thanks\", \"thanks!\", \"ThAnKs\" ‚Üí sabka matlab ek hi hai, but model will treat them as different words unless normalized.\n",
        "\n",
        "2. üî£ Remove Noise\n",
        "Punctuation, emojis, special characters often don't contribute to core meaning in many tasks (e.g., classification).\n",
        "\n",
        "3. üî° Standardization of Text\n",
        "Ensures that different representations of the same word are treated the same.\n",
        "\n",
        "E.g., \"I‚Äôm\" ‚Üí \"I am\", \"u\" ‚Üí \"you\"\n",
        "\n",
        "4. üìâ Reduce Vocabulary Size\n",
        "Helps in reducing the number of unique tokens, which is crucial for memory, speed, and performance.\n",
        "\n",
        "5. ü§ñ Improves Model Accuracy\n",
        "Cleaner and consistent input = better learning = higher accuracy.\n",
        "\n",
        "\n",
        "‚ú® Examples of Normalization:\n",
        "\n",
        "| Task                          | Example Input      | After Normalization |\n",
        "| ----------------------------- | ------------------ | ------------------- |\n",
        "| Lowercasing                   | `\"HELLO World!\"`   | `\"hello world!\"`    |\n",
        "| Removing punctuation          | `\"Wow!!!\"`         | `\"Wow\"`             |\n",
        "| Expanding contractions        | `\"don‚Äôt\"`          | `\"do not\"`          |\n",
        "| Removing stopwords (optional) | `\"this is a test\"` | `\"test\"`            |\n",
        "| Lemmatization                 | `\"running\"`        | `\"run\"`             |\n",
        "| Removing numbers (optional)   | `\"Price is 500\"`   | `\"Price is\"`        |\n"
      ],
      "metadata": {
        "id": "fjqHOA-RwaR1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDnLWnZswUa9",
        "outputId": "da0f1166-e5cb-4817-d5bc-72454d11cc9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World Lets codepython AI\n"
          ]
        }
      ],
      "source": [
        "#special characters\n",
        "import string\n",
        "\n",
        "text=\"Hello World! Let's code:#python #AI.\"\n",
        "translator=str.maketrans('','',string.punctuation)\n",
        "cleaned_text=text.translate(translator)\n",
        "print(cleaned_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"My Name is Dev PANDEY @123@589\"\n",
        "text=text.replace(\"PANDEY\",\"pandey\")\n",
        "print(text)\n",
        "# Combine punctuation + digits for deletion\n",
        "delete_chars = string.punctuation + string.digits\n",
        "translator=str.maketrans(\"MND\",\"mnd\",delete_chars)\n",
        "cleaned_text=text.translate(translator)\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R-PQ3jNy3tE",
        "outputId": "a783526b-9734-44f9-fab7-9b5a55b60ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My Name is Dev pandey @123@589\n",
            "my name is dev pandey \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#removing white spaces\n",
        "text=\"  Hello.  world.   \"\n",
        "cleaned_text=\" \".join(text.split())\n",
        "print(cleaned_text)\n",
        "print(len(text))\n",
        "print(len(cleaned_text))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_-UzTvPy30F",
        "outputId": "b4e284ce-ef45-424c-9a1e-2651be2276a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello. world.\n",
            "19\n",
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets work on contractions (eg:don't)\n",
        "#you need to install the library contractions\n",
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48Tl4f-Iy37u",
        "outputId": "2c99c899-bbef-49e2-a596-cf48512d2fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m113.9/113.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.3 contractions-0.1.73 pyahocorasick-2.2.0 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import contractions\n",
        "text=\"I don't like coding at night\"\n",
        "\n",
        "expanded_text=contractions.fix(text)\n",
        "print(expanded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmcAhYfPy3_L",
        "outputId": "4a8e37dd-980a-4721-fd32-db8367448e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I do not like coding at night\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"don't,shouldn't,wouldn't,shalln't\"\n",
        "\n",
        "expanded_text=contractions.fix(text)\n",
        "print(expanded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2fLuMYCy4Cx",
        "outputId": "1001c9d8-e025-44ab-cd05-4d46fe075e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "do not,should not,would not,shall not\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#handling numbers\n",
        "cleaned_text=\"\"\n",
        "num_to_digit={'2':\"two\",'3':'three'}\n",
        "text=\"I have 2 apples and 3 oranges\"\n",
        "for char in text:\n",
        "  if char.isdigit():\n",
        "    cleaned_text+=num_to_digit[char]\n",
        "  else:\n",
        "    cleaned_text+=char\n",
        "\n",
        "print(cleaned_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gErXkssiIboF",
        "outputId": "7b7dce40-5857-48b2-a8d4-eed6f9718d0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have two apples and three oranges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if number is not important for context\n",
        "import re\n",
        "\n",
        "cleaned_text=re.sub(r'\\d+',\"\",text)\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQbq8JcXIbrY",
        "outputId": "d1838896-df26-4e56-f971-8898d42d3634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have two apples and  oranges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#handling emails URLs Hastags\n",
        "import re\n",
        "text=\"Visit http://example.com for more info.Contact us at contact@example.com #AI\"\n",
        "processed_text=re.sub(r\"http\\S+|www\\S|https\\S+\",\"URL\",text)\n",
        "processed_text"
      ],
      "metadata": {
        "id": "Pl19uM89Ibu7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "952655c7-5eb9-4641-8b9d-e29a4fd11c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Visit URL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Spell checker\n",
        "!pip install pyspellchecker"
      ],
      "metadata": {
        "id": "6LCPQRUhIbyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed80c6cb-d444-477a-99ea-ef5efcac4ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.3-py3-none-any.whl.metadata (9.5 kB)\n",
            "Downloading pyspellchecker-0.8.3-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spellchecker import SpellChecker\n",
        "text=\"My name is dev pandey\"\n",
        "spell=SpellChecker()\n",
        "words=text.split()\n",
        "corrected_text=\" \".join([spell.correction(word)for word in words])\n",
        "print(corrected_text)"
      ],
      "metadata": {
        "id": "HE96gbsEIb1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b4f82f-5dc3-4b36-a32e-7cbd117a9e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is de pander\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Yes, it usually gives wrong output for names, places, technical terms, and uncommon words.\n",
        "üß† Reason: Ye library ke paas limited dictionary vocabulary hoti hai, mainly common English words ke liye.\n",
        "\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "text = \"My name is dev pandey\"\n",
        "spell = SpellChecker()\n",
        "words = text.split()\n",
        "corrected_text = \" \".join([spell.correction(word) for word in words])\n",
        "print(corrected_text)\n",
        "\n",
        "ü§î Why This Happens?\n",
        "The SpellChecker library uses:\n",
        "Probability-based word frequency model\n",
        "Looks up every word in its predefined dictionary (no names or custom words)\n",
        "Tries to find the closest word by edit distance (Levenshtein Distance)\n",
        "Names like \"dev\", \"pandey\" are not in dictionary, so it \"guesses\" similar known words.\n",
        "\n",
        "\n",
        "spell.word_frequency.load_words(['dev', 'pandey'])\n",
        "\n",
        "spell = SpellChecker()\n",
        "spell.word_frequency.load_words(['dev', 'pandey'])\n",
        "text = \"My name is dev pandey\"\n",
        "words = text.split()\n",
        "corrected_text = \" \".join([spell.correction(word) for word in words])\n",
        "print(corrected_text)\n"
      ],
      "metadata": {
        "id": "7mWB2ZLs9x_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X76SAwuRIb4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ODNG_5OfIb8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ze_4Yg7RIb_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y8MgoNj-IcH6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}